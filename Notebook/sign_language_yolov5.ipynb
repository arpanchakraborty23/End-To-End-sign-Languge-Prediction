{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\computer vision\\\\object_detaction\\\\End-To-End-sign-Languge-Prediction\\\\Notebook'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\object_detaction\\End-To-End-sign-Languge-Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\cv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\computer vision\\\\object_detaction\\\\End-To-End-sign-Languge-Prediction\\\\Notebook'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\object_detaction\\End-To-End-sign-Languge-Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\cv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'CH', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'LL', 'N', 'O', 'P', 'Q', 'R', 'RR', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'manos']\n"
     ]
    }
   ],
   "source": [
    "# define no of class\n",
    "import yaml\n",
    "with open('data.yaml','r') as y:\n",
    "   num_class=yaml.safe_load(y)['names']\n",
    "   \n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom model config\n",
    "file_path='yolov5/models/yolov5s.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ultralytics YOLOv5 ðŸš€, AGPL-3.0 license\n",
      "\n",
      "# Parameters\n",
      "nc: 80 # number of classes\n",
      "depth_multiple: 0.33 # model depth multiple\n",
      "width_multiple: 0.50 # layer channel multiple\n",
      "anchors:\n",
      "  - [10, 13, 16, 30, 33, 23] # P3/8\n",
      "  - [30, 61, 62, 45, 59, 119] # P4/16\n",
      "  - [116, 90, 156, 198, 373, 326] # P5/32\n",
      "\n",
      "# YOLOv5 v6.0 backbone\n",
      "backbone:\n",
      "  # [from, number, module, args]\n",
      "  [\n",
      "    [-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2\n",
      "    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\n",
      "    [-1, 3, C3, [128]],\n",
      "    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\n",
      "    [-1, 6, C3, [256]],\n",
      "    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\n",
      "    [-1, 9, C3, [512]],\n",
      "    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\n",
      "    [-1, 3, C3, [1024]],\n",
      "    [-1, 1, SPPF, [1024, 5]], # 9\n",
      "  ]\n",
      "\n",
      "# YOLOv5 v6.0 head\n",
      "head: [\n",
      "    [-1, 1, Conv, [512, 1, 1]],\n",
      "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
      "    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n",
      "    [-1, 3, C3, [512, False]], # 13\n",
      "\n",
      "    [-1, 1, Conv, [256, 1, 1]],\n",
      "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
      "    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n",
      "    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n",
      "\n",
      "    [-1, 1, Conv, [256, 3, 2]],\n",
      "    [[-1, 14], 1, Concat, [1]], # cat head P4\n",
      "    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n",
      "\n",
      "    [-1, 1, Conv, [512, 3, 2]],\n",
      "    [[-1, 10], 1, Concat, [1]], # cat head P5\n",
      "    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n",
      "\n",
      "    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n",
      "  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        print(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\object_detaction\\End-To-End-sign-Languge-Prediction\\Notebook\n"
     ]
    }
   ],
   "source": [
    "%cd Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\computer vision\\\\object_detaction\\\\End-To-End-sign-Languge-Prediction\\\\Notebook'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#customize iPython writefile so we can write variables\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@ register_line_cell_magic\n",
    "def writerTemplate(line,cell):\n",
    "    with open(line,'w') as f:\n",
    "      f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'yolov5'\n",
      "e:\\computer vision\\object_detaction\\End-To-End-sign-Languge-Prediction\\Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\cv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writerTemplate custom_model.yaml\n",
    "# Parameters\n",
    "nc: {num_class} # number of classes\n",
    "depth_multiple: 0.33 # model depth multiple\n",
    "width_multiple: 0.50 # layer channel multiple\n",
    "anchors:\n",
    "  - [10, 13, 16, 30, 33, 23] # P3/8\n",
    "  - [30, 61, 62, 45, 59, 119] # P4/16\n",
    "  - [116, 90, 156, 198, 373, 326] # P5/32\n",
    "\n",
    "# YOLOv5 v6.0 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [\n",
    "    [-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2\n",
    "    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\n",
    "    [-1, 3, C3, [128]],\n",
    "    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\n",
    "    [-1, 6, C3, [256]],\n",
    "    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\n",
    "    [-1, 9, C3, [512]],\n",
    "    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\n",
    "    [-1, 3, C3, [1024]],\n",
    "    [-1, 1, SPPF, [1024, 5]], # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 v6.0 head\n",
    "head: [\n",
    "    [-1, 1, Conv, [512, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
    "    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n",
    "    [-1, 3, C3, [512, False]], # 13\n",
    "\n",
    "    [-1, 1, Conv, [256, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
    "    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n",
    "    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n",
    "\n",
    "    [-1, 1, Conv, [256, 3, 2]],\n",
    "    [[-1, 14], 1, Concat, [1]], # cat head P4\n",
    "    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n",
    "\n",
    "    [-1, 1, Conv, [512, 3, 2]],\n",
    "    [[-1, 10], 1, Concat, [1]], # cat head P5\n",
    "    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n",
    "\n",
    "    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom YOLOv5 Detector\n",
    "Next, we'll fire off training!\n",
    "Here, we are able to pass a number of arguments:\n",
    "\n",
    "* img: define input image size\n",
    "* batch: determine batch size\n",
    "* epochs: define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "* data: set the path to our yaml file\n",
    "* cfg: specify our model configuration\n",
    "* weights: specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive folder)\n",
    "* name: result names\n",
    "* nosave: only save the final checkpoint\n",
    "* cache: cache images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\object_detaction\\End-To-End-sign-Languge-Prediction\n",
      "e:\\computer vision\\object_detaction\\End-To-End-sign-Languge-Prediction\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\computer vision\\cv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%cd ..\n",
    "%cd yolov5/\n",
    "!python train.py --img 416 --batch 16 --epochs 50 --data custom_data.yaml --cfg custom_model.yaml --weights yolov5s.pt --name yolov5s_results  --cache\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\computer vision\\\\object_detaction\\\\End-To-End-sign-Languge-Prediction\\\\yolov5'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
